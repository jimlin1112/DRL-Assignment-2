{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/100000 | Avg Score: 5664.20 | Success Rate: 0.00\n",
      "Episode 200/100000 | Avg Score: 5797.20 | Success Rate: 0.00\n",
      "Episode 300/100000 | Avg Score: 5380.68 | Success Rate: 0.00\n",
      "Episode 400/100000 | Avg Score: 5581.28 | Success Rate: 0.00\n",
      "Episode 500/100000 | Avg Score: 5727.52 | Success Rate: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 488\u001b[0m\n\u001b[1;32m    483\u001b[0m state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# Run TD-Learning training\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# Note: To achieve significantly better performance, you will likely need to train for over 100,000 episodes.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# However, to quickly verify that your implementation is working correctly, you can start by running it for 1,000 episodes before scaling up.\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m final_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtd_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapproximator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1e5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 449\u001b[0m, in \u001b[0;36mtd_learning\u001b[0;34m(env, approximator, num_episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_episodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Avg Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Success Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuccess_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 449\u001b[0m             \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapproximator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_scores\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit\n",
    "\n",
    "save_path = \"ntuple_approximator.pkl\"\n",
    "\n",
    "COLOR_MAP = {\n",
    "    0: \"#cdc1b4\", 2: \"#eee4da\", 4: \"#ede0c8\", 8: \"#f2b179\",\n",
    "    16: \"#f59563\", 32: \"#f67c5f\", 64: \"#f65e3b\", 128: \"#edcf72\",\n",
    "    256: \"#edcc61\", 512: \"#edc850\", 1024: \"#edc53f\", 2048: \"#edc22e\",\n",
    "    4096: \"#3c3a32\", 8192: \"#3c3a32\", 16384: \"#3c3a32\", 32768: \"#3c3a32\"\n",
    "}\n",
    "TEXT_COLOR = {\n",
    "    2: \"#776e65\", 4: \"#776e65\", 8: \"#f9f6f2\", 16: \"#f9f6f2\",\n",
    "    32: \"#f9f6f2\", 64: \"#f9f6f2\", 128: \"#f9f6f2\", 256: \"#f9f6f2\",\n",
    "    512: \"#f9f6f2\", 1024: \"#f9f6f2\", 2048: \"#f9f6f2\", 4096: \"#f9f6f2\"\n",
    "}\n",
    "\n",
    "@jit(nopython=True)\n",
    "def compress_and_merge(row, score):\n",
    "    size = 4\n",
    "    # 過濾非零元素\n",
    "    temp = np.zeros(size, dtype=np.int32)\n",
    "    pos = 0\n",
    "    for i in range(size):\n",
    "        if row[i] != 0:\n",
    "            temp[pos] = row[i]\n",
    "            pos += 1\n",
    "\n",
    "    # 合併相鄰相同元素\n",
    "    result = np.zeros(size, dtype=np.int32)\n",
    "    write_pos = 0\n",
    "    i = 0\n",
    "    while i < pos:\n",
    "        if i + 1 < pos and temp[i] == temp[i + 1]:\n",
    "            result[write_pos] = temp[i] * 2\n",
    "            score += temp[i] * 2\n",
    "            i += 2\n",
    "        else:\n",
    "            result[write_pos] = temp[i]\n",
    "            i += 1\n",
    "        write_pos += 1\n",
    "\n",
    "    return result, score\n",
    "\n",
    "@jit(nopython=True)\n",
    "def move_board(board, direction, score):\n",
    "    new_board = board.copy()\n",
    "    moved = False\n",
    "    if direction == 0:  # 上\n",
    "        for j in range(4):\n",
    "            col, new_score = compress_and_merge(new_board[:, j], score)\n",
    "            if not np.array_equal(col, new_board[:, j]):\n",
    "                moved = True\n",
    "            new_board[:, j] = col\n",
    "            score = new_score\n",
    "    elif direction == 1:  # 下\n",
    "        for j in range(4):\n",
    "            col = new_board[::-1, j]\n",
    "            col, new_score = compress_and_merge(col, score)\n",
    "            if not np.array_equal(col, new_board[::-1, j]):\n",
    "                moved = True\n",
    "            new_board[::-1, j] = col\n",
    "            score = new_score\n",
    "    elif direction == 2:  # 左\n",
    "        for i in range(4):\n",
    "            row, new_score = compress_and_merge(new_board[i], score)\n",
    "            if not np.array_equal(row, new_board[i]):\n",
    "                moved = True\n",
    "            new_board[i] = row\n",
    "            score = new_score\n",
    "    elif direction == 3:  # 右\n",
    "        for i in range(4):\n",
    "            row = new_board[i, ::-1]\n",
    "            row, new_score = compress_and_merge(row, score)\n",
    "            if not np.array_equal(row, new_board[i, ::-1]):\n",
    "                moved = True\n",
    "            new_board[i, ::-1] = row\n",
    "            score = new_score\n",
    "    return new_board, moved, score\n",
    "\n",
    "class Game2048Env(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(Game2048Env, self).__init__()\n",
    "\n",
    "        self.size = 4\n",
    "        self.board = np.zeros((self.size, self.size), dtype=int)\n",
    "        self.score = 0\n",
    "\n",
    "        # Action space: 0: up, 1: down, 2: left, 3: right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "\n",
    "        self.last_move_valid = True\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.size, self.size), dtype=int)\n",
    "        self.score = 0\n",
    "        self.add_random_tile()\n",
    "        self.add_random_tile()\n",
    "        return self.board\n",
    "\n",
    "    def add_random_tile(self):\n",
    "        # empty_cells = list(zip(*np.where(self.board == 0)))\n",
    "        # if empty_cells:\n",
    "        #     x, y = random.choice(empty_cells)\n",
    "        #     self.board[x, y] = 2 if random.random() < 0.9 else 4\n",
    "        empty_cells = np.where(self.board == 0)\n",
    "        if len(empty_cells[0]) > 0:\n",
    "            idx = random.randint(0, len(empty_cells[0]) - 1)\n",
    "            x, y = empty_cells[0][idx], empty_cells[1][idx]\n",
    "            self.board[x, y] = 2 if random.random() < 0.9 else 4\n",
    "\n",
    "    def compress(self, row):\n",
    "        new_row = row[row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode='constant')\n",
    "        return new_row\n",
    "\n",
    "    def merge(self, row):\n",
    "        for i in range(len(row) - 1):\n",
    "            if row[i] == row[i + 1] and row[i] != 0:\n",
    "                row[i] *= 2\n",
    "                row[i + 1] = 0\n",
    "                self.score += row[i]\n",
    "        return row\n",
    "\n",
    "    def move_left(self):\n",
    "        moved = False\n",
    "        for i in range(self.size):\n",
    "            original_row = self.board[i].copy()\n",
    "            new_row = self.compress(self.board[i])\n",
    "            new_row = self.merge(new_row)\n",
    "            new_row = self.compress(new_row)\n",
    "            self.board[i] = new_row\n",
    "            if not np.array_equal(original_row, self.board[i]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_right(self):\n",
    "        moved = False\n",
    "        for i in range(self.size):\n",
    "            original_row = self.board[i].copy()\n",
    "            reversed_row = self.board[i][::-1]\n",
    "            reversed_row = self.compress(reversed_row)\n",
    "            reversed_row = self.merge(reversed_row)\n",
    "            reversed_row = self.compress(reversed_row)\n",
    "            self.board[i] = reversed_row[::-1]\n",
    "            if not np.array_equal(original_row, self.board[i]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_up(self):\n",
    "        moved = False\n",
    "        for j in range(self.size):\n",
    "            original_col = self.board[:, j].copy()\n",
    "            col = self.compress(self.board[:, j])\n",
    "            col = self.merge(col)\n",
    "            col = self.compress(col)\n",
    "            self.board[:, j] = col\n",
    "            if not np.array_equal(original_col, self.board[:, j]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_down(self):\n",
    "        moved = False\n",
    "        for j in range(self.size):\n",
    "            original_col = self.board[:, j].copy()\n",
    "            reversed_col = self.board[:, j][::-1]\n",
    "            reversed_col = self.compress(reversed_col)\n",
    "            reversed_col = self.merge(reversed_col)\n",
    "            reversed_col = self.compress(reversed_col)\n",
    "            self.board[:, j] = reversed_col[::-1]\n",
    "            if not np.array_equal(original_col, self.board[:, j]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def is_game_over(self):\n",
    "        if np.any(self.board == 0):\n",
    "            return False\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size - 1):\n",
    "                if self.board[i, j] == self.board[i, j+1]:\n",
    "                    return False\n",
    "        for j in range(self.size):\n",
    "            for i in range(self.size - 1):\n",
    "                if self.board[i, j] == self.board[i+1, j]:\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"Invalid action\"\n",
    "\n",
    "        # if action == 0:\n",
    "        #     moved = self.move_up()\n",
    "        # elif action == 1:\n",
    "        #     moved = self.move_down()\n",
    "        # elif action == 2:\n",
    "        #     moved = self.move_left()\n",
    "        # elif action == 3:\n",
    "        #     moved = self.move_right()\n",
    "        # else:\n",
    "        #     moved = False\n",
    "\n",
    "        self.board, moved, self.score = move_board(self.board, action, self.score)\n",
    "\n",
    "        self.last_move_valid = moved\n",
    "\n",
    "        if moved:\n",
    "            self.add_random_tile()\n",
    "\n",
    "        done = self.is_game_over()\n",
    "\n",
    "        return self.board, self.score, done, {}\n",
    "\n",
    "    def render(self, mode=\"human\", action=None):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(-0.5, self.size - 0.5)\n",
    "        ax.set_ylim(-0.5, self.size - 0.5)\n",
    "\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                value = self.board[i, j]\n",
    "                color = COLOR_MAP.get(value, \"#3c3a32\")\n",
    "                text_color = TEXT_COLOR.get(value, \"white\")\n",
    "                rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, facecolor=color, edgecolor=\"black\")\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "                if value != 0:\n",
    "                    ax.text(j, i, str(value), ha='center', va='center',\n",
    "                            fontsize=16, fontweight='bold', color=text_color)\n",
    "        title = f\"score: {self.score}\"\n",
    "        if action is not None:\n",
    "            title += f\" | action: {self.actions[action]}\"\n",
    "        plt.title(title)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "\n",
    "    def simulate_row_move(self, row):\n",
    "        new_row = row[row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode='constant')\n",
    "        for i in range(len(new_row) - 1):\n",
    "            if new_row[i] == new_row[i + 1] and new_row[i] != 0:\n",
    "                new_row[i] *= 2\n",
    "                new_row[i + 1] = 0\n",
    "        new_row = new_row[new_row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode='constant')\n",
    "        return new_row\n",
    "\n",
    "\n",
    "    def is_move_legal(self, action):\n",
    "        temp_board = self.board.copy()\n",
    "\n",
    "        # if action == 0:  # Move up\n",
    "        #     for j in range(self.size):\n",
    "        #         col = temp_board[:, j]\n",
    "        #         new_col = self.simulate_row_move(col)\n",
    "        #         temp_board[:, j] = new_col\n",
    "        # elif action == 1:  # Move down\n",
    "        #     for j in range(self.size):\n",
    "        #         col = temp_board[:, j][::-1]\n",
    "        #         new_col = self.simulate_row_move(col)\n",
    "        #         temp_board[:, j] = new_col[::-1]\n",
    "        # elif action == 2:  # Move left\n",
    "        #     for i in range(self.size):\n",
    "        #         row = temp_board[i]\n",
    "        #         temp_board[i] = self.simulate_row_move(row)\n",
    "        # elif action == 3:  # Move right\n",
    "        #     for i in range(self.size):\n",
    "        #         row = temp_board[i][::-1]\n",
    "        #         new_row = self.simulate_row_move(row)\n",
    "        #         temp_board[i] = new_row[::-1]\n",
    "        # else:\n",
    "        #     raise ValueError(\"Invalid action\")\n",
    "        # return not np.array_equal(self.board, temp_board)\n",
    "\n",
    "        new_board, moved, _ = move_board(temp_board, action, self.score)\n",
    "        return moved\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# TODO: Define transformation functions (rotation and reflection), i.e., rot90, rot180, ..., etc.\n",
    "# -------------------------------\n",
    "def rot90(pattern, board_size):\n",
    "    return [(j, board_size - 1 - i) for (i, j) in pattern]\n",
    "\n",
    "def rot180(pattern, board_size):\n",
    "    return [(board_size - 1 - i, board_size - 1 - j) for (i, j) in pattern]\n",
    "\n",
    "def rot270(pattern, board_size):\n",
    "    return [(board_size - 1 - j, i) for (i, j) in pattern]\n",
    "\n",
    "def reflect(pattern, board_size):\n",
    "    return [(i, board_size - 1 - j) for (i, j) in pattern]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NTupleApproximator:\n",
    "    def __init__(self, board_size, patterns):\n",
    "        \"\"\"\n",
    "        Initializes the N-Tuple approximator.\n",
    "        Hint: you can adjust these if you want\n",
    "        \"\"\"\n",
    "        self.board_size = board_size\n",
    "        self.patterns = patterns\n",
    "        # Create a weight dictionary for each pattern (shared within a pattern group)\n",
    "        self.weights = [defaultdict(float) for _ in patterns]\n",
    "        # Generate symmetrical transformations for each pattern\n",
    "        self.symmetry_patterns = []\n",
    "        self.symmetry_groups = []\n",
    "        for pattern in self.patterns:\n",
    "            syms = self.generate_symmetries(pattern)\n",
    "            self.symmetry_groups.append(syms)\n",
    "            for syms_ in syms:\n",
    "                self.symmetry_patterns.append(syms_)\n",
    "\n",
    "    def generate_symmetries(self, pattern):\n",
    "        # TODO: Generate 8 symmetrical transformations of the given pattern.\n",
    "        board_size = self.board_size\n",
    "        sym0 = pattern\n",
    "        sym1 = rot90(pattern, board_size)\n",
    "        sym2 = rot180(pattern, board_size)\n",
    "        sym3 = rot270(pattern, board_size)\n",
    "        syms = [sym0, sym1, sym2, sym3,\n",
    "              reflect(sym0, board_size),\n",
    "              reflect(sym1, board_size),\n",
    "              reflect(sym2, board_size),\n",
    "              reflect(sym3, board_size)]\n",
    "        return syms\n",
    "\n",
    "\n",
    "    def tile_to_index(self, tile):\n",
    "        \"\"\"\n",
    "        Converts tile values to an index for the lookup table.\n",
    "        \"\"\"\n",
    "        if tile == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return int(math.log(tile, 2))\n",
    "\n",
    "    def get_feature(self, board, coords):\n",
    "        # TODO: Extract tile values from the board based on the given coordinates and convert them into a feature tuple.\n",
    "        return tuple(self.tile_to_index(board[i, j]) for (i, j) in coords)\n",
    "\n",
    "\n",
    "    def value(self, board):\n",
    "        # TODO: Estimate the board value: sum the evaluations from all patterns.\n",
    "        total_value = 0.0\n",
    "        for i, syms in enumerate(self.symmetry_groups):\n",
    "            group_value = 0.0\n",
    "            for pattern in syms:\n",
    "                feature = self.get_feature(board, pattern)\n",
    "                group_value += self.weights[i][feature]\n",
    "            total_value += group_value / len(syms)\n",
    "        return total_value\n",
    "\n",
    "    def update(self, board, delta, alpha):\n",
    "        # TODO: Update weights based on the TD error.\n",
    "        for i, syms in enumerate(self.symmetry_groups):\n",
    "            update_value = alpha * delta / len(syms)\n",
    "            for pattern in syms:\n",
    "                feature = self.get_feature(board, pattern)\n",
    "                self.weights[i][feature] += update_value\n",
    "\n",
    "def td_learning(env, approximator, num_episodes=50000, alpha=0.01, gamma=0.99, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Trains the 2048 agent using TD-Learning.\n",
    "\n",
    "    Args:\n",
    "        env: The 2048 game environment.\n",
    "        approximator: NTupleApproximator instance.\n",
    "        num_episodes: Number of training episodes.\n",
    "        alpha: Learning rate.\n",
    "        gamma: Discount factor.\n",
    "        epsilon: Epsilon-greedy exploration rate.\n",
    "    \"\"\"\n",
    "    final_scores = []\n",
    "    success_flags = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        trajectory = []  # Store trajectory data if needed\n",
    "        previous_score = 0\n",
    "        done = False\n",
    "        max_tile = np.max(state)\n",
    "\n",
    "        while not done:\n",
    "            legal_moves = [a for a in range(4) if env.is_move_legal(a)]\n",
    "            if not legal_moves:\n",
    "                break\n",
    "            # TODO: action selection\n",
    "            # Note: TD learning works fine on 2048 without explicit exploration, but you can still try some exploration methods.\n",
    "            if random.random() < epsilon and episode < 50000:\n",
    "                action = random.choice(legal_moves)\n",
    "            else:\n",
    "                # Evaluate each legal move\n",
    "                values = []\n",
    "                for a in legal_moves:\n",
    "                    env_copy = copy.deepcopy(env)\n",
    "                    next_state, reward, done, _ = env_copy.step(a)\n",
    "                    value = approximator.value(next_state)\n",
    "                    values.append(value)\n",
    "                action = legal_moves[np.argmax(values)]\n",
    "\n",
    "\n",
    "            next_state, new_score, done, _ = env.step(action)\n",
    "            incremental_reward = new_score - previous_score\n",
    "            previous_score = new_score\n",
    "            max_tile = max(max_tile, np.max(next_state))\n",
    "\n",
    "            # TODO: Store trajectory or just update depending on the implementation\n",
    "            old_value = approximator.value(state)\n",
    "            if done:\n",
    "                target = incremental_reward\n",
    "            else:\n",
    "                target = incremental_reward + gamma * approximator.value(next_state)\n",
    "            delta = target - old_value\n",
    "\n",
    "            approximator.update(state, delta, alpha)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        # TODO: If you are storing the trajectory, consider updating it now depending on your implementation.\n",
    "\n",
    "\n",
    "        final_scores.append(env.score)\n",
    "        success_flags.append(1 if max_tile >= 2048 else 0)\n",
    "\n",
    "        if (episode + 1) % 100 == 0:\n",
    "            avg_score = np.mean(final_scores[-100:])\n",
    "            success_rate = np.sum(success_flags[-100:]) / 100\n",
    "            print(f\"Episode {episode+1}/{num_episodes} | Avg Score: {avg_score:.2f} | Success Rate: {success_rate:.2f}\", flush=True)\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                pickle.dump(approximator, f)\n",
    "\n",
    "    return final_scores\n",
    "\n",
    "\n",
    "# TODO: Define your own n-tuple patterns\n",
    "# patterns = []\n",
    "patterns = [\n",
    "    # 行 Patterns\n",
    "    [(0,0), (0,1), (0,2), (0,3)],\n",
    "    [(1,0), (1,1), (1,2), (1,3)],\n",
    "    # 2x2 方塊 Patterns\n",
    "    [(0,0), (0,1), (1,0), (1,1)],\n",
    "    [(1,1), (1,2), (2,1), (2,2)],\n",
    "    [(0,1), (0,2), (1,1), (1,2)],\n",
    "    # 對角線 Patterns\n",
    "    [(0,0), (1,1), (2,2), (3,3)],\n",
    "    # 四角\n",
    "    [(0,0), (0,3), (3,0), (3,3)],\n",
    "    # T\n",
    "    [(0,0), (0,1), (0,2), (1,1)],\n",
    "    [(0,0), (1,0), (2,0), (3,0), (2,1), (2,2), (2,3)],\n",
    "    # L\n",
    "    [(0,0), (1,0), (2,0), (2,1)],\n",
    "    [(0,0), (1,0), (2,0), (3,0), (3,1), (3,2), (3,3)],\n",
    "    # S\n",
    "    [(0,1), (0,2), (1,0), (1,1)],\n",
    "]\n",
    "\n",
    "# approximator = NTupleApproximator(board_size=4, patterns=patterns)\n",
    "with open(save_path, \"rb\") as f:\n",
    "    approximator = pickle.load(f)\n",
    "\n",
    "env = Game2048Env()\n",
    "state = env.reset()\n",
    "\n",
    "# Run TD-Learning training\n",
    "# Note: To achieve significantly better performance, you will likely need to train for over 100,000 episodes.\n",
    "# However, to quickly verify that your implementation is working correctly, you can start by running it for 1,000 episodes before scaling up.\n",
    "final_scores = td_learning(env, approximator, num_episodes=int(1e5), alpha=0.1, gamma=0.99, epsilon=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
