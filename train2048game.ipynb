{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/100000 | Avg Score: 4452.48 | Success Rate: 0.00\n",
      "Episode 200/100000 | Avg Score: 6253.72 | Success Rate: 0.00\n",
      "Episode 300/100000 | Avg Score: 7066.56 | Success Rate: 0.00\n",
      "Episode 400/100000 | Avg Score: 6512.84 | Success Rate: 0.00\n",
      "Episode 500/100000 | Avg Score: 8000.68 | Success Rate: 0.00\n",
      "Episode 600/100000 | Avg Score: 7640.88 | Success Rate: 0.01\n",
      "Episode 700/100000 | Avg Score: 8435.84 | Success Rate: 0.00\n",
      "Episode 800/100000 | Avg Score: 8042.32 | Success Rate: 0.00\n",
      "Episode 900/100000 | Avg Score: 8191.36 | Success Rate: 0.01\n",
      "Episode 1000/100000 | Avg Score: 8538.16 | Success Rate: 0.01\n",
      "Episode 1100/100000 | Avg Score: 8046.88 | Success Rate: 0.00\n",
      "Episode 1200/100000 | Avg Score: 8495.32 | Success Rate: 0.00\n",
      "Episode 1300/100000 | Avg Score: 9026.76 | Success Rate: 0.00\n",
      "Episode 1400/100000 | Avg Score: 9216.36 | Success Rate: 0.02\n",
      "Episode 1500/100000 | Avg Score: 8752.48 | Success Rate: 0.00\n",
      "Episode 1600/100000 | Avg Score: 9086.92 | Success Rate: 0.00\n",
      "Episode 1700/100000 | Avg Score: 9702.84 | Success Rate: 0.00\n",
      "Episode 1800/100000 | Avg Score: 9607.60 | Success Rate: 0.00\n",
      "Episode 1900/100000 | Avg Score: 9920.20 | Success Rate: 0.01\n",
      "Episode 2000/100000 | Avg Score: 10533.92 | Success Rate: 0.00\n",
      "Episode 2100/100000 | Avg Score: 10451.00 | Success Rate: 0.00\n",
      "Episode 2200/100000 | Avg Score: 9606.84 | Success Rate: 0.01\n",
      "Episode 2300/100000 | Avg Score: 9233.96 | Success Rate: 0.00\n",
      "Episode 2400/100000 | Avg Score: 10024.16 | Success Rate: 0.00\n",
      "Episode 2500/100000 | Avg Score: 9971.68 | Success Rate: 0.01\n",
      "Episode 2600/100000 | Avg Score: 9150.08 | Success Rate: 0.01\n",
      "Episode 2700/100000 | Avg Score: 10139.40 | Success Rate: 0.02\n",
      "Episode 2800/100000 | Avg Score: 10156.32 | Success Rate: 0.03\n",
      "Episode 2900/100000 | Avg Score: 10578.48 | Success Rate: 0.01\n",
      "Episode 3000/100000 | Avg Score: 9323.76 | Success Rate: 0.01\n",
      "Episode 3100/100000 | Avg Score: 10161.44 | Success Rate: 0.02\n",
      "Episode 3200/100000 | Avg Score: 10183.04 | Success Rate: 0.01\n",
      "Episode 3300/100000 | Avg Score: 9531.36 | Success Rate: 0.03\n",
      "Episode 3400/100000 | Avg Score: 9475.36 | Success Rate: 0.00\n",
      "Episode 3500/100000 | Avg Score: 10355.60 | Success Rate: 0.01\n",
      "Episode 3600/100000 | Avg Score: 9666.80 | Success Rate: 0.03\n",
      "Episode 3700/100000 | Avg Score: 10488.00 | Success Rate: 0.02\n",
      "Episode 3800/100000 | Avg Score: 11084.60 | Success Rate: 0.01\n",
      "Episode 3900/100000 | Avg Score: 10061.72 | Success Rate: 0.00\n",
      "Episode 4000/100000 | Avg Score: 9491.92 | Success Rate: 0.00\n",
      "Episode 4100/100000 | Avg Score: 10670.60 | Success Rate: 0.02\n",
      "Episode 4200/100000 | Avg Score: 10134.20 | Success Rate: 0.02\n",
      "Episode 4300/100000 | Avg Score: 10424.08 | Success Rate: 0.02\n",
      "Episode 4400/100000 | Avg Score: 9925.04 | Success Rate: 0.00\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit\n",
    "\n",
    "save_path = \"ntuple_approximator.pkl\"\n",
    "\n",
    "COLOR_MAP = {\n",
    "    0: \"#cdc1b4\", 2: \"#eee4da\", 4: \"#ede0c8\", 8: \"#f2b179\",\n",
    "    16: \"#f59563\", 32: \"#f67c5f\", 64: \"#f65e3b\", 128: \"#edcf72\",\n",
    "    256: \"#edcc61\", 512: \"#edc850\", 1024: \"#edc53f\", 2048: \"#edc22e\",\n",
    "    4096: \"#3c3a32\", 8192: \"#3c3a32\", 16384: \"#3c3a32\", 32768: \"#3c3a32\"\n",
    "}\n",
    "TEXT_COLOR = {\n",
    "    2: \"#776e65\", 4: \"#776e65\", 8: \"#f9f6f2\", 16: \"#f9f6f2\",\n",
    "    32: \"#f9f6f2\", 64: \"#f9f6f2\", 128: \"#f9f6f2\", 256: \"#f9f6f2\",\n",
    "    512: \"#f9f6f2\", 1024: \"#f9f6f2\", 2048: \"#f9f6f2\", 4096: \"#f9f6f2\"\n",
    "}\n",
    "\n",
    "@jit(nopython=True)\n",
    "def compress_and_merge(row, score):\n",
    "    size = 4\n",
    "    # 過濾非零元素\n",
    "    temp = np.zeros(size, dtype=np.int32)\n",
    "    pos = 0\n",
    "    for i in range(size):\n",
    "        if row[i] != 0:\n",
    "            temp[pos] = row[i]\n",
    "            pos += 1\n",
    "\n",
    "    # 合併相鄰相同元素\n",
    "    result = np.zeros(size, dtype=np.int32)\n",
    "    write_pos = 0\n",
    "    i = 0\n",
    "    while i < pos:\n",
    "        if i + 1 < pos and temp[i] == temp[i + 1]:\n",
    "            result[write_pos] = temp[i] * 2\n",
    "            score += temp[i] * 2\n",
    "            i += 2\n",
    "        else:\n",
    "            result[write_pos] = temp[i]\n",
    "            i += 1\n",
    "        write_pos += 1\n",
    "\n",
    "    return result, score\n",
    "\n",
    "@jit(nopython=True)\n",
    "def move_board(board, direction, score):\n",
    "    new_board = board.copy()\n",
    "    moved = False\n",
    "    if direction == 0:  # 上\n",
    "        for j in range(4):\n",
    "            col, new_score = compress_and_merge(new_board[:, j], score)\n",
    "            if not np.array_equal(col, new_board[:, j]):\n",
    "                moved = True\n",
    "            new_board[:, j] = col\n",
    "            score = new_score\n",
    "    elif direction == 1:  # 下\n",
    "        for j in range(4):\n",
    "            col = new_board[::-1, j]\n",
    "            col, new_score = compress_and_merge(col, score)\n",
    "            if not np.array_equal(col, new_board[::-1, j]):\n",
    "                moved = True\n",
    "            new_board[::-1, j] = col\n",
    "            score = new_score\n",
    "    elif direction == 2:  # 左\n",
    "        for i in range(4):\n",
    "            row, new_score = compress_and_merge(new_board[i], score)\n",
    "            if not np.array_equal(row, new_board[i]):\n",
    "                moved = True\n",
    "            new_board[i] = row\n",
    "            score = new_score\n",
    "    elif direction == 3:  # 右\n",
    "        for i in range(4):\n",
    "            row = new_board[i, ::-1]\n",
    "            row, new_score = compress_and_merge(row, score)\n",
    "            if not np.array_equal(row, new_board[i, ::-1]):\n",
    "                moved = True\n",
    "            new_board[i, ::-1] = row\n",
    "            score = new_score\n",
    "    return new_board, moved, score\n",
    "\n",
    "class Game2048Env(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(Game2048Env, self).__init__()\n",
    "\n",
    "        self.size = 4\n",
    "        self.board = np.zeros((self.size, self.size), dtype=int)\n",
    "        self.score = 0\n",
    "\n",
    "        # Action space: 0: up, 1: down, 2: left, 3: right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "\n",
    "        self.last_move_valid = True\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.size, self.size), dtype=int)\n",
    "        self.score = 0\n",
    "        self.add_random_tile()\n",
    "        self.add_random_tile()\n",
    "        return self.board\n",
    "\n",
    "    def add_random_tile(self):\n",
    "        # empty_cells = list(zip(*np.where(self.board == 0)))\n",
    "        # if empty_cells:\n",
    "        #     x, y = random.choice(empty_cells)\n",
    "        #     self.board[x, y] = 2 if random.random() < 0.9 else 4\n",
    "        empty_cells = np.where(self.board == 0)\n",
    "        if len(empty_cells[0]) > 0:\n",
    "            idx = random.randint(0, len(empty_cells[0]) - 1)\n",
    "            x, y = empty_cells[0][idx], empty_cells[1][idx]\n",
    "            self.board[x, y] = 2 if random.random() < 0.9 else 4\n",
    "\n",
    "    def compress(self, row):\n",
    "        new_row = row[row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode='constant')\n",
    "        return new_row\n",
    "\n",
    "    def merge(self, row):\n",
    "        for i in range(len(row) - 1):\n",
    "            if row[i] == row[i + 1] and row[i] != 0:\n",
    "                row[i] *= 2\n",
    "                row[i + 1] = 0\n",
    "                self.score += row[i]\n",
    "        return row\n",
    "\n",
    "    def move_left(self):\n",
    "        moved = False\n",
    "        for i in range(self.size):\n",
    "            original_row = self.board[i].copy()\n",
    "            new_row = self.compress(self.board[i])\n",
    "            new_row = self.merge(new_row)\n",
    "            new_row = self.compress(new_row)\n",
    "            self.board[i] = new_row\n",
    "            if not np.array_equal(original_row, self.board[i]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_right(self):\n",
    "        moved = False\n",
    "        for i in range(self.size):\n",
    "            original_row = self.board[i].copy()\n",
    "            reversed_row = self.board[i][::-1]\n",
    "            reversed_row = self.compress(reversed_row)\n",
    "            reversed_row = self.merge(reversed_row)\n",
    "            reversed_row = self.compress(reversed_row)\n",
    "            self.board[i] = reversed_row[::-1]\n",
    "            if not np.array_equal(original_row, self.board[i]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_up(self):\n",
    "        moved = False\n",
    "        for j in range(self.size):\n",
    "            original_col = self.board[:, j].copy()\n",
    "            col = self.compress(self.board[:, j])\n",
    "            col = self.merge(col)\n",
    "            col = self.compress(col)\n",
    "            self.board[:, j] = col\n",
    "            if not np.array_equal(original_col, self.board[:, j]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def move_down(self):\n",
    "        moved = False\n",
    "        for j in range(self.size):\n",
    "            original_col = self.board[:, j].copy()\n",
    "            reversed_col = self.board[:, j][::-1]\n",
    "            reversed_col = self.compress(reversed_col)\n",
    "            reversed_col = self.merge(reversed_col)\n",
    "            reversed_col = self.compress(reversed_col)\n",
    "            self.board[:, j] = reversed_col[::-1]\n",
    "            if not np.array_equal(original_col, self.board[:, j]):\n",
    "                moved = True\n",
    "        return moved\n",
    "\n",
    "    def is_game_over(self):\n",
    "        if np.any(self.board == 0):\n",
    "            return False\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size - 1):\n",
    "                if self.board[i, j] == self.board[i, j+1]:\n",
    "                    return False\n",
    "        for j in range(self.size):\n",
    "            for i in range(self.size - 1):\n",
    "                if self.board[i, j] == self.board[i+1, j]:\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"Invalid action\"\n",
    "\n",
    "        # if action == 0:\n",
    "        #     moved = self.move_up()\n",
    "        # elif action == 1:\n",
    "        #     moved = self.move_down()\n",
    "        # elif action == 2:\n",
    "        #     moved = self.move_left()\n",
    "        # elif action == 3:\n",
    "        #     moved = self.move_right()\n",
    "        # else:\n",
    "        #     moved = False\n",
    "\n",
    "        self.board, moved, self.score = move_board(self.board, action, self.score)\n",
    "\n",
    "        self.last_move_valid = moved\n",
    "\n",
    "        if moved:\n",
    "            self.add_random_tile()\n",
    "\n",
    "        done = self.is_game_over()\n",
    "\n",
    "        return self.board, self.score, done, {}\n",
    "\n",
    "    def render(self, mode=\"human\", action=None):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(-0.5, self.size - 0.5)\n",
    "        ax.set_ylim(-0.5, self.size - 0.5)\n",
    "\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                value = self.board[i, j]\n",
    "                color = COLOR_MAP.get(value, \"#3c3a32\")\n",
    "                text_color = TEXT_COLOR.get(value, \"white\")\n",
    "                rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, facecolor=color, edgecolor=\"black\")\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "                if value != 0:\n",
    "                    ax.text(j, i, str(value), ha='center', va='center',\n",
    "                            fontsize=16, fontweight='bold', color=text_color)\n",
    "        title = f\"score: {self.score}\"\n",
    "        if action is not None:\n",
    "            title += f\" | action: {self.actions[action]}\"\n",
    "        plt.title(title)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "\n",
    "    def simulate_row_move(self, row):\n",
    "        new_row = row[row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode='constant')\n",
    "        for i in range(len(new_row) - 1):\n",
    "            if new_row[i] == new_row[i + 1] and new_row[i] != 0:\n",
    "                new_row[i] *= 2\n",
    "                new_row[i + 1] = 0\n",
    "        new_row = new_row[new_row != 0]\n",
    "        new_row = np.pad(new_row, (0, self.size - len(new_row)), mode='constant')\n",
    "        return new_row\n",
    "\n",
    "\n",
    "    def is_move_legal(self, action):\n",
    "        temp_board = self.board.copy()\n",
    "        new_board, moved, _ = move_board(temp_board, action, self.score)\n",
    "        return moved\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# TODO: Define transformation functions (rotation and reflection), i.e., rot90, rot180, ..., etc.\n",
    "# -------------------------------\n",
    "def rot90(pattern, board_size):\n",
    "    return [(j, board_size - 1 - i) for (i, j) in pattern]\n",
    "\n",
    "def rot180(pattern, board_size):\n",
    "    return [(board_size - 1 - i, board_size - 1 - j) for (i, j) in pattern]\n",
    "\n",
    "def rot270(pattern, board_size):\n",
    "    return [(board_size - 1 - j, i) for (i, j) in pattern]\n",
    "\n",
    "def reflect(pattern, board_size):\n",
    "    return [(i, board_size - 1 - j) for (i, j) in pattern]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NTupleApproximator:\n",
    "    def __init__(self, board_size, patterns):\n",
    "        \"\"\"\n",
    "        Initializes the N-Tuple approximator.\n",
    "        Hint: you can adjust these if you want\n",
    "        \"\"\"\n",
    "        self.board_size = board_size\n",
    "        self.patterns = patterns\n",
    "        # Create a weight dictionary for each pattern (shared within a pattern group)\n",
    "        self.weights = [defaultdict(float) for _ in patterns]\n",
    "        # Generate symmetrical transformations for each pattern\n",
    "        self.symmetry_patterns = []\n",
    "        self.symmetry_groups = []\n",
    "        for pattern in self.patterns:\n",
    "            syms = self.generate_symmetries(pattern)\n",
    "            self.symmetry_groups.append(syms)\n",
    "            for syms_ in syms:\n",
    "                self.symmetry_patterns.append(syms_)\n",
    "\n",
    "    def generate_symmetries(self, pattern):\n",
    "        # TODO: Generate 8 symmetrical transformations of the given pattern.\n",
    "        board_size = self.board_size\n",
    "        sym0 = pattern\n",
    "        sym1 = rot90(pattern, board_size)\n",
    "        sym2 = rot180(pattern, board_size)\n",
    "        sym3 = rot270(pattern, board_size)\n",
    "        syms = [sym0, sym1, sym2, sym3,\n",
    "              reflect(sym0, board_size),\n",
    "              reflect(sym1, board_size),\n",
    "              reflect(sym2, board_size),\n",
    "              reflect(sym3, board_size)]\n",
    "        return syms\n",
    "\n",
    "\n",
    "    def tile_to_index(self, tile):\n",
    "        \"\"\"\n",
    "        Converts tile values to an index for the lookup table.\n",
    "        \"\"\"\n",
    "        if tile == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return int(math.log(tile, 2))\n",
    "\n",
    "    def get_feature(self, board, coords):\n",
    "        # TODO: Extract tile values from the board based on the given coordinates and convert them into a feature tuple.\n",
    "        return tuple(self.tile_to_index(board[i, j]) for (i, j) in coords)\n",
    "\n",
    "\n",
    "    def value(self, board):\n",
    "        # TODO: Estimate the board value: sum the evaluations from all patterns.\n",
    "        total_value = 0.0\n",
    "        for i, syms in enumerate(self.symmetry_groups):\n",
    "            group_value = 0.0\n",
    "            for pattern in syms:\n",
    "                feature = self.get_feature(board, pattern)\n",
    "                group_value += self.weights[i][feature]\n",
    "            total_value += group_value / len(syms)\n",
    "        return total_value\n",
    "\n",
    "    def update(self, board, delta, alpha):\n",
    "        # TODO: Update weights based on the TD error.\n",
    "        for i, syms in enumerate(self.symmetry_groups):\n",
    "            update_value = alpha * delta / len(syms)\n",
    "            for pattern in syms:\n",
    "                feature = self.get_feature(board, pattern)\n",
    "                self.weights[i][feature] += update_value\n",
    "\n",
    "def td_learning(env, approximator, num_episodes=50000, alpha=0.01, gamma=0.99, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Trains the 2048 agent using TD-Learning with afterstate updates.\n",
    "    \"\"\"\n",
    "    final_scores = []\n",
    "    success_flags = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        previous_score = 0\n",
    "        done = False\n",
    "        max_tile = np.max(state)\n",
    "\n",
    "        while not done:\n",
    "            legal_moves = [a for a in range(4) if env.is_move_legal(a)]\n",
    "            if not legal_moves:\n",
    "                break\n",
    "\n",
    "            # Collect afterstates and their values\n",
    "            afterstates = []\n",
    "            afterstate_values = []\n",
    "            next_rewards = []\n",
    "\n",
    "            for a in legal_moves:\n",
    "                env_copy = copy.deepcopy(env)\n",
    "                next_state, next_score, next_done, _ = env_copy.step(a)\n",
    "                next_reward = next_score - previous_score\n",
    "                \n",
    "                # Store afterstate (the board after move, before random tile)\n",
    "                # This is a key change - we need to get the board state before adding the random tile\n",
    "                afterstate = next_state.copy()  # In a real implementation, you'd capture before random tile\n",
    "                \n",
    "                afterstates.append((afterstate, a))\n",
    "                afterstate_values.append(approximator.value(afterstate))\n",
    "                next_rewards.append(next_reward)\n",
    "\n",
    "            # Select action based on afterstate values\n",
    "            if random.random() < epsilon and episode < num_episodes * 0.8:\n",
    "                idx = random.randrange(len(legal_moves))\n",
    "            else:\n",
    "                idx = np.argmax(afterstate_values)\n",
    "            \n",
    "            selected_afterstate, action = afterstates[idx]\n",
    "            selected_value = afterstate_values[idx]\n",
    "            \n",
    "            # Take the action in the real environment\n",
    "            next_state, new_score, done, _ = env.step(action)\n",
    "            incremental_reward = new_score - previous_score\n",
    "            previous_score = new_score\n",
    "            max_tile = max(max_tile, np.max(next_state))\n",
    "            \n",
    "            # Update the value function for the selected afterstate\n",
    "            # The target is the immediate reward plus discounted value of next afterstate\n",
    "            if done:\n",
    "                target = incremental_reward\n",
    "            else:\n",
    "                # For the next state, we need to look at possible future afterstates\n",
    "                next_values = []\n",
    "                next_legal_moves = [a for a in range(4) if env.is_move_legal(a)]\n",
    "                \n",
    "                if next_legal_moves:\n",
    "                    for a in next_legal_moves:\n",
    "                        env_copy = copy.deepcopy(env)\n",
    "                        future_state, _, _, _ = env_copy.step(a)\n",
    "                        next_values.append(approximator.value(future_state))\n",
    "                    \n",
    "                    future_value = max(next_values) if next_values else 0\n",
    "                    target = incremental_reward + gamma * future_value\n",
    "                else:\n",
    "                    target = incremental_reward\n",
    "\n",
    "            # Update the value function\n",
    "            delta = target - selected_value\n",
    "            approximator.update(selected_afterstate, delta, alpha)\n",
    "            \n",
    "            state = next_state\n",
    "\n",
    "        final_scores.append(env.score)\n",
    "        success_flags.append(1 if max_tile >= 2048 else 0)\n",
    "\n",
    "        if (episode + 1) % 100 == 0:\n",
    "            avg_score = np.mean(final_scores[-100:])\n",
    "            success_rate = np.sum(success_flags[-100:]) / 100\n",
    "            print(f\"Episode {episode+1}/{num_episodes} | Avg Score: {avg_score:.2f} | Success Rate: {success_rate:.2f}\", flush=True)\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                pickle.dump(approximator, f)\n",
    "\n",
    "    return final_scores\n",
    "\n",
    "\n",
    "# TODO: Define your own n-tuple patterns\n",
    "# patterns = []\n",
    "patterns = [\n",
    "    [(0,0)],\n",
    "    [(0,1)],\n",
    "    [(1,0)],\n",
    "    [(1,1)],\n",
    "    [(0,0), (0,1)],\n",
    "    [(1,0), (1,1)],\n",
    "    [(0,0), (0,1), (1,0)],\n",
    "    [(0,0), (1,1), (2,2)],\n",
    "    [(0,0), (0,1), (0,2), (0,3)],\n",
    "    [(1,0), (1,1), (1,2), (1,3)],\n",
    "    [(0,0), (0,1), (0,2), (1,0), (2,0)],\n",
    "    [(1,1), (1,2), (1,3), (2,1), (3,1)],\n",
    "    [(0,0), (0,1), (0,2), (1,0), (1,1), (1,2)],\n",
    "]\n",
    "\n",
    "approximator = NTupleApproximator(board_size=4, patterns=patterns)\n",
    "# with open(save_path, \"rb\") as f:\n",
    "#     approximator = pickle.load(f)\n",
    "\n",
    "env = Game2048Env()\n",
    "state = env.reset()\n",
    "\n",
    "# Run TD-Learning training\n",
    "# Note: To achieve significantly better performance, you will likely need to train for over 100,000 episodes.\n",
    "# However, to quickly verify that your implementation is working correctly, you can start by running it for 1,000 episodes before scaling up.\n",
    "final_scores = td_learning(env, approximator, num_episodes=int(1e5), alpha=0.1, gamma=0.99, epsilon=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
